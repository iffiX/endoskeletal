{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-26T00:41:18.102814Z",
     "start_time": "2024-11-26T00:41:18.099265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The robot history file here (Path for demonstration)\n",
    "robot_history_path = \"/home/mlw0504/Projects/rise-gen-data/RIS-167-records/epoch_462/bot_e_460_ro_70.h5_history\"\n",
    "video_blend_file = \"/home/mlw0504/Projects/rise-gen/data/blender/video_simple.blend\"\n",
    "data_dir = \"/home/mlw0504/Projects/rise-gen/data/video\"\n",
    "output_name = \"bot_167_462_70.blend\"\n",
    "\n",
    "# Number of record frames used to produce one keyframe in the video\n",
    "frame_interval = 1\n",
    "\n",
    "# Visualize mode\n",
    "# mode = \"simple_transparent\"\n",
    "mode = \"voxels\""
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T23:42:15.612172Z",
     "start_time": "2024-11-25T23:42:15.609236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "def color_map(normalized_stress: np.ndarray):\n",
    "    colors = np.zeros([normalized_stress.shape[0], 3], dtype=np.float32)\n",
    "    cmap = plt.get_cmap(\"jet\")\n",
    "    for idx, stress in enumerate(normalized_stress):\n",
    "        colors[idx] = cmap(stress - 1e-5)[:3]\n",
    "    return colors"
   ],
   "id": "db96c661b79cbfd",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T00:47:32.514616Z",
     "start_time": "2024-11-26T00:41:20.289406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import bpy\n",
    "from tqdm import tqdm\n",
    "from visualize.blender.reader import RiseSimulationDataReader\n",
    "from visualize.blender.generate import compute_transform_for_align_trajectory_to_y, generate_robot\n",
    "from visualize.blender.scene import setup_scene\n",
    "\n",
    "setup_scene(video_blend_file,\n",
    "            use_gpu=True)\n",
    "\n",
    "# Use the RS_SimulationDataReader to read the data\n",
    "with RiseSimulationDataReader(robot_history_path) as reader:\n",
    "    transform = compute_transform_for_align_trajectory_to_y(reader)\n",
    "    \n",
    "    # Create a new collection named \"video\" and link it to the scene\n",
    "    video_collection_name = \"video\"\n",
    "    if video_collection_name in bpy.data.collections:\n",
    "        video_collection = bpy.data.collections[video_collection_name]\n",
    "    else:\n",
    "        video_collection = bpy.data.collections.new(video_collection_name)\n",
    "        bpy.context.scene.collection.children.link(video_collection)\n",
    "\n",
    "    # Loop through all frames\n",
    "    frames = list(range(0, len(reader), frame_interval))\n",
    "    real_frame_index = 0\n",
    "    for frame_index in tqdm(frames):\n",
    "        # Create a new collection for this frame\n",
    "        frame_collection_name = f\"frame_{frame_index}\"\n",
    "        frame_collection = bpy.data.collections.new(frame_collection_name)\n",
    "\n",
    "        # Link the frame collection under the \"video\" collection\n",
    "        video_collection.children.link(frame_collection)\n",
    "\n",
    "        # Read voxel data for the current frame\n",
    "        voxel_data = reader.read_voxel_data(frame_index)\n",
    "        positions, orientations = voxel_data[\"position\"], voxel_data[\"orientation\"]\n",
    "        transformed_positions, _ = transform(positions, orientations)\n",
    "        transformed_com = np.mean(transformed_positions, axis=0)\n",
    "\n",
    "        # Generate the robot in the scene\n",
    "        robot_objects = generate_robot(\n",
    "            frame_collection,\n",
    "            reader,\n",
    "            frame_index,\n",
    "            color_map=color_map,\n",
    "            transform=transform,\n",
    "            mode=mode,\n",
    "            voxel_size=0.01\n",
    "        )\n",
    "\n",
    "        # For each object in the robot, set visibility keyframes\n",
    "        for obj in frame_collection.objects:\n",
    "            # Initially hide the object\n",
    "            obj.hide_viewport = True\n",
    "            obj.hide_render = True\n",
    "\n",
    "            # Insert keyframes for hiding the object\n",
    "            obj.keyframe_insert(data_path=\"hide_viewport\", frame=real_frame_index - 1)\n",
    "            obj.keyframe_insert(data_path=\"hide_render\", frame=real_frame_index - 1)\n",
    "\n",
    "            # Show the object on the current frame\n",
    "            obj.hide_viewport = False\n",
    "            obj.hide_render = False\n",
    "\n",
    "            # Insert keyframes for showing the object\n",
    "            obj.keyframe_insert(data_path=\"hide_viewport\", frame=real_frame_index)\n",
    "            obj.keyframe_insert(data_path=\"hide_render\", frame=real_frame_index)\n",
    "\n",
    "            # Hide the object again on the next frame\n",
    "            obj.hide_viewport = True\n",
    "            obj.hide_render = True\n",
    "\n",
    "            # Insert keyframes for hiding the object\n",
    "            obj.keyframe_insert(data_path=\"hide_viewport\", frame=real_frame_index + 1)\n",
    "            obj.keyframe_insert(data_path=\"hide_render\", frame=real_frame_index + 1)\n",
    "        real_frame_index += 1\n",
    "\n",
    "# Save the modified Blender file\n",
    "bpy.ops.wm.save_as_mainfile(filepath=os.path.join(data_dir, output_name))\n"
   ],
   "id": "5482c5adfa31ef92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File written by newer Blender binary (402.66), expect loss of data!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 713/713 [06:10<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read blend: \"/home/mlw0504/Projects/rise-gen/data/blender/video_simple.blend\"\n",
      "Warning: region type 14 missing in space type \"Image\" (id: 6) - removing region\n",
      "regiondata free error\n",
      "Warning: region type 15 missing in space type \"Image\" (id: 6) - removing region\n",
      "Warning: region type 14 missing in space type \"Image\" (id: 6) - removing region\n",
      "regiondata free error\n",
      "Warning: region type 15 missing in space type \"Image\" (id: 6) - removing region\n",
      "Warning: region type 14 missing in space type \"Image\" (id: 6) - removing region\n",
      "regiondata free error\n",
      "Warning: region type 15 missing in space type \"Image\" (id: 6) - removing region\n",
      "Warning: region type 14 missing in space type \"Image\" (id: 6) - removing region\n",
      "regiondata free error\n",
      "Warning: region type 15 missing in space type \"Image\" (id: 6) - removing region\n",
      "Info: Total files 0 | Changed 0 | Failed 0\n",
      "Info: Saved \"bot_167_600_18.blend\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'FINISHED'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
